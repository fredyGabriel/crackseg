# Main Hydra configuration for experiment runner - BASIC VERIFICATION SETUP
# This file sets up the default configuration structure for the project.

# List of default configuration files to load for each component
# The order matters. _self_ ensures this file is loaded last.
defaults:
  - base                  # Base global settings
  - data: default         # General data config
  - data/transform: augmentations  # Data augmentations
  - data/dataloader: default       # DataLoader config
  - model: default        # Model config - simplified
  - training: default     # Training config - 2 epochs
  - evaluation: default   # Evaluation config
  - _self_

# General configuration
random_seed: 42           # Global random seed for reproducibility
require_cuda: false       # Do NOT require CUDA (allow CPU for testing)
log_level: "INFO"         # Logging level: DEBUG, INFO, WARNING, ERROR, CRITICAL
log_to_file: true         # Save logs to file in addition to console

# Experiment configuration
experiment:
  name: "basic_verification"  # Name of the experiment - CHANGED for testing
  output_dir: "outputs"       # Directory for all experiment outputs

# Configure Hydra to use the same directory structure as ExperimentManager
hydra:
  run:
    dir: artifacts/outputs/experiments/${now:%Y%m%d-%H%M%S}-${hydra.job.name}  # Output dir for single runs
  sweep:
    dir: artifacts/outputs/multirun/${now:%Y%m%d-%H%M%S}                      # Output dir for sweeps
    subdir: ${hydra.job.num}                                        # Subdir for each sweep job
  job:
    chdir: false            # Do not change working directory

# Pre-declare model node to allow command-line overrides
model: {}

# Data configuration (legacy, for backward compatibility)
data:
  root_dir: "data"         # Root directory for all data
  train_dir: "${data.root_dir}/train"  # Training data directory
  val_dir: "${data.root_dir}/val"      # Validation data directory
  test_dir: "${data.root_dir}/test"    # Test data directory
  batch_size: 4            # Batch size (legacy, overridden by dataloader config) - REDUCED
  num_workers: 2           # Number of workers (legacy) - REDUCED
  pin_memory: true         # Pin memory for DataLoader (legacy)

# Model configuration - This entire section will be loaded via defaults
# (see model/default.yaml and model subfolders for details)
# model:
#   name: "unet"
#   encoder:
#     backbone: "resnet34"
#     pretrained: true
#     input_channels: 3
#   bottleneck:
#     type: "simple"
#   decoder:
#     type: "unet"
#     use_attention: true

# Training configuration - This entire section will be loaded via defaults
# (see training/default.yaml and training subfolders for details)
# training:
#   num_epochs: 100
#   optimizer:
#     type: "adam"
#     lr: 0.001
#     weight_decay: 0.0001
#   scheduler:
#     type: "reduce_on_plateau"
#     patience: 5
#     factor: 0.5
#   loss:
#     type: "bce_dice"
#     dice_weight: 0.5
#   early_stopping:
#     enabled: true
#     patience: 10
#     min_delta: 0.001
#   amp_enabled: true  # Automatic Mixed Precision
#   checkpoints:
#     save_freq: 5  # Save every N epochs
#     checkpoint_dir: "checkpoints"
#     save_best:
#       enabled: true
#       monitor_metric: "val_dice"
#       monitor_mode: "max"  # or "min" for losses

# Evaluation configuration - This entire section will be loaded via defaults
# (see evaluation/default.yaml for details)
# evaluation:
#   metrics:
#     iou: {}
#     dice: {}
#     precision: {}
#     recall: {}
#     accuracy: {}
