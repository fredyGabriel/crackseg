# Tutorial 02: Swin-UNet Architecture Experiment Configuration
#
# This configuration tests Swin-UNet architecture for crack segmentation.
# Swin-UNet combines Swin Transformer encoder with CNN decoder for
# better multi-scale feature extraction, which is important for detecting
# cracks of varying widths (1-5 pixels to large structural damage).
#
# Reference: docs/tutorials/02_custom_experiment_cli.md

# Hydra configuration composition - inherits from base config
defaults:
  - /base  # Base configuration with all components
  - _self_ # This file overrides base settings

# Model architecture override - Swin-UNet with Swin-T encoder
model:
  _target_: crackseg.model.core.unet.BaseUNet  # Main model class
  encoder:
    _target_: src.model.factory.create_encoder  # Factory function for encoder
    type: "SwinTransformerEncoder"             # Use Swin Transformer as encoder
    in_channels: 3                             # Number of input channels (e.g., RGB)
    model_name: "swinv2_tiny_window16_256"     # SwinV2 model variant
    pretrained: true                           # Use ImageNet pretrained weights
    img_size: 256                              # Input image size for SwinV2
    patch_size: 4                              # Patch size for Swin Transformer
    handle_input_size: "resize"                # Resize input images for compatibility
    output_hidden_states: true                  # Output all hidden states
    features_only: true                        # Only output feature maps
    out_indices: [0, 1, 2, 3]                  # Indices of feature maps to use as skips
    output_norm: true                          # Apply normalization to output features
  bottleneck:
    _target_: src.model.factory.create_bottleneck  # Factory function for bottleneck
    type: "ASPPModule"                         # Use ASPP bottleneck
    # For swinv2_tiny_window16_256, feature channels are [96, 192, 384, 768]
    # Bottleneck receives last feature map (768 channels)
    in_channels: 768
    output_channels: 256
    dilation_rates: [1, 6, 12, 18]
    dropout_rate: 0.1
    output_stride: 16
  decoder:
    _target_: src.model.factory.create_decoder     # Factory function for decoder
    type: "CNNDecoder"                           # Use CNN decoder
    in_channels: 256                             # Match bottleneck output channels
    # Skip connection channels for swinv2_tiny_window16_256 (reverse order)
    # [384, 192, 96] from encoder's skip_channels
    skip_channels_list: [384, 192, 96]
    out_channels: 1                               # Binary segmentation by default
    depth: 3                                      # Swin model has 3 skip connections
    config:
      upsample_scale_factor: 2
      upsample_mode: "bilinear"
      kernel_size: 3
      padding: 1
      use_cbam: false
      cbam_reduction: 16

# Training hyperparameters override
training:
  learning_rate: 0.0001  # Default learning rate for Swin-UNet
  epochs: 100            # More epochs for complex architecture convergence

# Override batch size for larger model (use command line: data.dataloader.batch_size=8)