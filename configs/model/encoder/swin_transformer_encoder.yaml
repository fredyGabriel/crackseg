# @package _group_

# Swin Transformer V2 Encoder Configuration
# Uses the Swin Transformer V2 architecture from timm and adapts it
# for use as an encoder in segmentation models like U-Net.

_target_: src.model.factory.create_encoder  # Factory function for encoder

type: SwinTransformerEncoder  # Registered name for this encoder

# === Basic Parameters ===
in_channels: 3  # Number of input channels (e.g., 3 for RGB, 1 for grayscale)

# === Swin Transformer V2 Model Options ===
# Model name from timm library. Options include:
# - swinv2_tiny_window16_256: Smallest model (8.8M params)
# - swinv2_small_window16_256: Medium (24.9M params)
# - swinv2_base_window16_256: Large (87.9M params)
# - swinv2_tiny_window8_256: Small, smaller window
# - swinv2_tiny_window16_384: Small, for 384Ã—384 inputs
model_name: "swinv2_tiny_window16_256"
pretrained: true  # Use pretrained weights from ImageNet

# Feature extraction options
output_hidden_states: true  # Return hidden states from all layers
features_only: true         # Return feature maps instead of classification output
out_indices: [0, 1, 2, 3]   # Feature indices to extract (0=highest res, 3=lowest)

# === Input Processing Options ===
img_size: 256      # Default input size expected by the model
patch_size: 4      # Patch size for embedding layer (typically 4)
handle_input_size: "resize"  # How to handle inputs with sizes different from img_size
# - "resize": Resize input to img_size (best for pretrained models)
# - "pad": Pad input to make divisible by patch_size (preserves aspect ratio)
# - "none": No special handling (may error if sizes are incompatible)

# === Validation Parameters ===
min_model_name_parts_for_size_check: 3 # Min parts in model_name to check size

# === Output Processing Options ===
use_abs_pos_embed: true  # Use absolute positional embeddings (default: true)
output_norm: true        # Apply layer normalization to output features (default: true)

# === Transfer Learning Options ===
freeze_layers: false  # Control which parts of the model are frozen during training
# - false: No freezing (default for full training)
# - true: Freeze all but the last block (common for transfer learning)
# - "all": Freeze the entire encoder (feature extraction only)
# - "patch_embed": Freeze only the patch embedding
# - "stages.0,stages.1": Freeze specific stages (comma-separated)

# Differential learning rates for fine-tuning
# Maps layer name patterns to learning rate scaling factors.
# Allows training different parts of the model with different learning rates.
finetune_lr_scale:
  patch_embed: 0.1  # Early layers: 10% of base LR
  stages.0: 0.2     # First stage: 20% of base LR
  stages.1: 0.5     # Middle stage: 50% of base LR
  stages.2: 1.0     # Later stage: 100% of base LR (base LR)