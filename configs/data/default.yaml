# Default data configuration
# NOTE: 'batch_size' and 'num_workers' are the single source of truth for all modules (including DataLoader). Edit them here to affect all data loading behavior.
# Edit these values for your dataset

data_root: data/           # Root directory for all dataset files
train_split: 0.7           # Fraction of data used for training
val_split: 0.15            # Fraction of data used for validation
test_split: 0.15           # Fraction of data used for testing
image_size: [256, 256]     # Target image size as [height, width] - REDUCED for faster testing
batch_size: 4              # Number of samples per batch - REDUCED for verification
num_workers: 2             # Number of worker processes for data loading - REDUCED for stability
seed: ${random_seed}       # Random seed for reproducibility (from base.yaml)
in_memory_cache: false     # Whether to cache data in memory (improves speed, uses more RAM)

# Tensor shape constants
num_dims_image: 4
num_channels_rgb: 3
num_dims_mask: 3
kernel_expected_dims: 2
expected_input_dims: 4 # Expected input dimensions (B, C, H, W)
expected_bottleneck_ndim_4d: 4 # Expected 4D bottleneck dimensions (B, C, H, W)
expected_bottleneck_ndim_3d: 3 # Expected 3D bottleneck dimensions (B, L, C)
num_dims_mask_pre_unsqueeze: 3 # Expected mask dimensions before unsqueeze