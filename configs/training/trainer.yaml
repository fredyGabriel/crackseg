# Training configuration for the trainer
# This file contains settings for the training process

# Training parameters
epochs: 100
learning_rate: 0.001
batch_size: 8
num_workers: 4
gradient_accumulation_steps: 1

# Device configuration
device: "auto"  # auto, cpu, cuda
require_cuda: false

# Optimizer configuration
optimizer:
  _target_: torch.optim.Adam
  lr: 0.001
  weight_decay: 0.0001
  betas: [0.9, 0.999]

# Scheduler configuration
scheduler:
  type: "step"
  step_size: 30
  gamma: 0.1

# Loss configuration
loss:
  type: "bce_dice"
  bce_weight: 0.5
  dice_weight: 0.5
  smooth: 1.0

# Checkpoint configuration
checkpoint_dir: "artifacts/experiments"  # Directory to save checkpoints
save_freq: 5  # Save every N epochs
save_best: true
monitor_metric: "val_dice"
monitor_mode: "max"

# Early stopping configuration
early_stopping:
  enabled: True
  patience: 10
  min_delta: 0.001
  should_stop: True

# Logging configuration
logging:
  log_freq: 10  # Log every N batches
  tensorboard: true
  wandb: false

# Validation configuration
validation:
  freq: 1  # Validate every N epochs
  save_predictions: true
  save_visualizations: true