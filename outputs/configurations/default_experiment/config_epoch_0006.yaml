training:
  _target_: crackseg.training.trainer.Trainer
  device: auto
  optimizer:
    _target_: torch.optim.Adam
    lr: 0.001
  lr_scheduler:
    _target_: torch.optim.lr_scheduler.StepLR
    step_size: 10
    gamma: 0.5
  use_amp: false
  gradient_accumulation_steps: 1
  checkpoint_dir: artifacts/checkpoints
  save_freq: 0
  save_best:
    enabled: true
    monitor_metric: val_loss
    monitor_mode: min
    best_filename: model_best.pth.tar
  early_stopping:
    _target_: crackseg.utils.early_stopping.EarlyStopping
    monitor: val_loss
    patience: 5
    mode: min
    min_delta: 0.01
    verbose: true
  verbose: true
  progress_bar: true
  log_interval_batches: 10
  loss:
    _target_: crackseg.training.losses.BCEDiceLoss
    config:
      _target_: crackseg.training.losses.bce_dice_loss.BCEDiceLossConfig
      bce_weight: 0.5
      dice_weight: 0.5
      dice_smooth: 1.0
      dice_sigmoid: true
      dice_eps: 1.0e-06
      bce_reduction: mean
      bce_pos_weight: null
  epochs: 10
  learning_rate: 0.001
  weight_decay: 0.0001
  scheduler: step_lr
  step_size: 10
  gamma: 0.5
model:
  _target_: crackseg.model.core.unet.BaseUNet
  encoder:
    _target_: crackseg.model.encoder.CNNEncoder
    in_channels: 3
    init_features: 16
    depth: 3
  bottleneck:
    _target_: crackseg.model.bottleneck.cnn_bottleneck.BottleneckBlock
    in_channels: 64
    out_channels: 128
  decoder:
    _target_: crackseg.model.decoder.cnn_decoder.CNNDecoder
    in_channels: 128
    skip_channels_list:
    - 64
    - 32
    - 16
    out_channels: 1
    depth: 3
  final_activation: null
data:
  data_root: data/unified/
  train_split: 0.7
  val_split: 0.15
  test_split: 0.15
  image_size:
  - 256
  - 256
  seed: 42
  in_memory_cache: false
  use_unified_splitting: true
  num_dims_image: 4
  num_channels_rgb: 3
  num_dims_mask: 3
  kernel_expected_dims: 2
  expected_input_dims: 4
  expected_bottleneck_ndim_4d: 4
  expected_bottleneck_ndim_3d: 3
  num_dims_mask_pre_unsqueeze: 3
  transform:
    train:
    - name: Resize
      params:
        height: 256
        width: 256
    - name: HorizontalFlip
      params:
        p: 0.5
    - name: VerticalFlip
      params:
        p: 0.5
    - name: Rotate
      params:
        limit: 90
        p: 0.5
    - name: ColorJitter
      params:
        brightness: 0.2
        contrast: 0.2
        saturation: 0.2
        hue: 0.1
        p: 0.3
    - name: Normalize
      params:
        mean:
        - 0.485
        - 0.456
        - 0.406
        std:
        - 0.229
        - 0.224
        - 0.225
    - name: ToTensorV2
      params: {}
    val:
    - name: Resize
      params:
        height: 256
        width: 256
    - name: Normalize
      params:
        mean:
        - 0.485
        - 0.456
        - 0.406
        std:
        - 0.229
        - 0.224
        - 0.225
    - name: ToTensorV2
      params: {}
    test:
    - name: Resize
      params:
        height: 256
        width: 256
    - name: Normalize
      params:
        mean:
        - 0.485
        - 0.456
        - 0.406
        std:
        - 0.229
        - 0.224
        - 0.225
    - name: ToTensorV2
      params: {}
  dataloader:
    batch_size: 4
    num_workers: 2
    shuffle: true
    pin_memory: true
    prefetch_factor: 2
    drop_last: false
    distributed:
      enabled: false
      rank: 0
      world_size: 1
    sampler:
      enabled: false
      kind: random
      shuffle: true
      seed: 42
    memory:
      fp16: false
      adaptive_batch_size: false
      max_memory_mb: null
    max_train_samples: 16
    max_val_samples: 8
    max_test_samples: 8
evaluation:
  metrics:
    iou:
      _target_: crackseg.training.metrics.IoUScore
      smooth: 1.0e-06
      threshold: 0.5
      expected_dims_before_squeeze: 4
      expected_dims_after_squeeze: 3
    f1:
      _target_: crackseg.training.metrics.F1Score
      smooth: 1.0e-06
      threshold: 0.5
      expected_dims_before_squeeze: 4
      expected_dims_after_squeeze: 3
    precision:
      _target_: crackseg.training.metrics.PrecisionScore
      smooth: 1.0e-06
      threshold: 0.5
      expected_dims_before_squeeze: 4
      expected_dims_after_squeeze: 3
    recall:
      _target_: crackseg.training.metrics.RecallScore
      smooth: 1.0e-06
      threshold: 0.5
      expected_dims_before_squeeze: 4
      expected_dims_after_squeeze: 3
  save_predictions: true
  save_dir: artifacts/evaluation_outputs/
  num_batches_visualize: 2
  visualize_samples: 5
project_name: crack-segmentation
output_dir: artifacts/outputs/
data_dir: data/
random_seed: 42
experiment:
  name: main_experiment
  output_dir: outputs
log_level: INFO
log_to_file: true
require_cuda: false
device: auto
timestamp_parsing:
  min_parts: 2
  date_len: 8
  time_len: 6
thresholds:
  default: 0.5
  metric: 0.5
  loss_weight: 0.5
  gamma: 0.5
visualization:
  num_cols: 3
  num_cols_no_targets: 2
experiments:
  swinv2_hybrid:
    model:
      _target_: crackseg.model.architectures.swinv2_cnn_aspp_unet.SwinV2CnnAsppUNet
      type: SwinV2CnnAsppUNet
      encoder:
        _target_: crackseg.model.encoder.swin_v2_adapter.SwinV2EncoderAdapter
        model_name: swinv2_tiny_window8_256
        img_size: 256
        target_img_size: 256
        in_channels: 3
      bottleneck:
        _target_: crackseg.model.components.aspp.ASPPModule
        in_channels: 768
        output_channels: 256
        dilation_rates:
        - 1
        - 6
        - 12
        - 18
        dropout_rate: 0.1
      decoder:
        _target_: crackseg.model.decoder.cnn_decoder.CNNDecoder
        in_channels: 256
        config:
          use_cbam: true
          cbam_reduction: 16
          upsample_mode: bilinear
          kernel_size: 3
          padding: 1
          upsample_scale_factor: 2
      num_classes: 1
      final_activation: sigmoid
    training:
      loss:
        _target_: crackseg.training.losses.focal_dice_loss.FocalDiceLoss
        config:
          _target_: crackseg.training.losses.focal_dice_loss.FocalDiceLossConfig
          focal_weight: 0.6
          dice_weight: 0.4
          focal_alpha: 0.25
          focal_gamma: 2.0
          focal_reduction: mean
          dice_smooth: 1.0
          dice_sigmoid: true
          dice_eps: 1.0e-06
          total_loss_weight: 1.0
      learning_rate: 0.0001
      batch_size: 4
      gradient_accumulation_steps: 4
      use_amp: true
      early_stopping_patience: 15
      optimizer:
        _target_: torch.optim.AdamW
        lr: 0.0001
        weight_decay: 0.01
        betas:
        - 0.9
        - 0.999
      scheduler:
        _target_: torch.optim.lr_scheduler.CosineAnnealingWarmRestarts
        T_0: 10
        T_mult: 2
        eta_min: 1.0e-06
    data:
      image_size:
      - 256
      - 256
      dataloader:
        batch_size: 4
        num_workers: 4
        pin_memory: true
        persistent_workers: true
        prefetch_factor: 2
        drop_last: true
    experiment:
      name: swinv2_hybrid_focal_dice
      description: SwinV2 + ASPP + CNN hybrid architecture with Focal Dice Loss
      tags:
      - hybrid_architecture
      - swinv2
      - aspp
      - focal_dice_loss
      - crack_segmentation
      - rtx3070ti_optimized
config_metadata:
  created_at: '2025-07-27T04:28:11.045884'
  config_hash: bdc0c88eac490f55
  format_version: '1.0'
environment:
  pytorch_version: 2.7.1
  python_version: 3.12.11
  platform: Windows-11-10.0.26100-SP0
  timestamp: '2025-07-27T04:28:11.055897'
  cuda_available: true
  cuda_version: available
  cuda_device_count: '1'
  cuda_device_name: NVIDIA GeForce RTX 3070 Ti Laptop GPU
