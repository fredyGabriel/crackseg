#!/usr/bin/env python3
"""
Advanced DataLoader configuration and creation for crack segmentation training.

This module provides sophisticated DataLoader creation capabilities with
support for:
- Adaptive batch sizing based on available GPU memory
- Automatic worker count configuration based on CPU cores
- Distributed training support with custom samplers
- Memory optimization for large datasets
- Comprehensive parameter validation and error handling

Key Features:
- Intelligent defaults for development and production use
- GPU memory-aware batch size adaptation to prevent OOM errors
- Flexible sampler configuration (random, sequential, distributed)
- Automatic num_workers detection based on system capabilities
- FP16 training support for memory efficiency
- Comprehensive validation and error reporting

The module is designed to work seamlessly with the crack segmentation project's
training pipeline while providing enough flexibility for various use cases:

- Development: Small batch sizes with debugging-friendly settings
- Production: Optimized settings for maximum training throughput
- Distributed: Multi-GPU and multi-node training support
- Resource-constrained: Adaptive settings for limited hardware

Examples:
    Basic DataLoader creation:
    ```python
    from  crackseg.data.dataloader  import  create_dataloader, DataLoaderConfig

    # Simple configuration
    dataloader = create_dataloader(
        dataset=train_dataset,
        batch_size=32
    )

    # Advanced configuration with memory management
    config = DataLoaderConfig(
        num_workers=8,
        pin_memory=True,
        adaptive_batch_size=True,
        max_memory_mb=8000
    )

    dataloader = create_dataloader(
        dataset=train_dataset,
        batch_size=64,
        config=config
    )
    ```

    Distributed training setup:
    ```python
    config = DataLoaderConfig(
        sampler_config={
            "kind": "distributed",
            "shuffle": True
        },
        rank=local_rank,
        world_size=world_size
    )

    dataloader = create_dataloader(dataset, batch_size=32, config=config)
    ```

Performance Considerations:
- num_workers=-1 automatically detects optimal worker count
- pin_memory=True speeds up GPU transfer on CUDA systems
- prefetch_factor controls memory vs speed tradeoff
- adaptive_batch_size prevents OOM while maximizing throughput

Integration:
- Designed for use with CrackSegmentationDataset
- Compatible with PyTorch distributed training
- Integrates with Hydra configuration system
- Supports both development and production workflows

See Also:
    - src.data.dataset: Dataset implementation
    - src.data.sampler: Custom sampler implementations
    - src.data.memory: GPU memory management utilities
    - configs/data/dataloader/: Configuration examples
"""
import os import warnings from dataclasses import dataclass from
typing import Any import torch from torch.utils.data import
DataLoader, Dataset, Sampler from .memory import
get_available_gpu_memory from .sampler import SamplerFactoryArgs,
sampler_factory @dataclass class DataLoaderConfig:
"""
    Comprehensive configuration for creating optimized PyTorch DataLoaders.

    This configuration class provides fine-grained control over DataLoader
    behavior with intelligent defaults for different use cases. It supports
    both simple configurations for development and advanced settings for
    production training.

    Attributes:
        num_workers: Number of worker processes for data loading.
            Use -1 for automatic detection (recommended).

        shuffle: Whether to shuffle data at every epoch.
            Automatically disabled when using custom samplers.

        pin_memory: Whether to pin memory for faster GPU transfer.
            Recommended True for CUDA training, False for CPU-only.

        prefetch_factor: Number of samples loaded in advance by each worker.
            Higher values use more memory but may improve throughput.

        sampler_config: Configuration for custom samplers.
            Dict with 'kind' key specifying sampler type and parameters.

        rank: Process rank for distributed training (0-based).
            Required when using distributed samplers.

        world_size: Total number of processes in distributed training.
            Required when using distributed samplers.

        fp16: Whether to enable FP16 optimizations.
            Enables memory optimizations for mixed precision training.

        max_memory_mb: Maximum GPU memory to use for adaptive batch sizing.
            Prevents OOM by limiting memory usage. None for no limit.

        adaptive_batch_size: Whether to enable automatic batch size adaptation.
            Adjusts batch size based on available GPU memory.

        dataloader_extra_kwargs: Additional keyword arguments for DataLoader.
            For advanced use cases requiring custom DataLoader parameters.

    Examples:
        Development configuration:
        ```python
        config = DataLoaderConfig(
            num_workers=2,
            shuffle=True,
            pin_memory=False,  # CPU training
            adaptive_batch_size=False
        )
        ```

        Production configuration:
        ```python
        config = DataLoaderConfig(
            num_workers=-1,  # Auto-detect
            pin_memory=True,
            adaptive_batch_size=True,
            max_memory_mb=12000,  # Limit for 16GB GPU
            fp16=True
        )
        ```

        Distributed training configuration:
        ```python
        config = DataLoaderConfig(
            sampler_config={
                "kind": "distributed",
                "shuffle": True,
                "drop_last": True
            },
            rank=local_rank,
            world_size=world_size,
            num_workers=8
        )
        ```

    Note:
        When using distributed samplers, shuffle is automatically set to False
        to avoid conflicts. The sampler handles shuffling internally.
    """
num_workers: int = -1 shuffle: bool = True pin_memory: bool = True
prefetch_factor: int = 2 sampler_config: dict[str, Any] | None = None
rank: int | None = None world_size: int | None = None fp16: bool =
False max_memory_mb: float | None = None adaptive_batch_size: bool =
False dataloader_extra_kwargs: dict[str, Any] | None = None def
_validate_dataloader_params(batch_size: int, prefetch_factor: int,
num_workers: int ) -> None:
"""
    Validate basic DataLoader parameters for correctness and safety.

    This function performs comprehensive validation of core DataLoader
    parameters to ensure they are within acceptable ranges and prevent
    common configuration errors that could lead to runtime failures.

    Args:
        batch_size: Number of samples per batch. Must be positive.
        prefetch_factor: Number of samples loaded in advance by each worker.
            Must be positive to ensure efficient data loading.
        num_workers: Number of worker processes. Must be >= -1 where -1
            indicates automatic detection.

    Raises:
        ValueError: If any parameter is outside acceptable range:
            - batch_size <= 0: Prevents empty or negative batches
            - prefetch_factor <= 0: Ensures efficient prefetching
            - num_workers < -1: Validates worker count specification

    Examples:
        Valid parameters:
        ```python
        _validate_dataloader_params(32, 2, 4)  # Standard configuration
        _validate_dataloader_params(16, 1, -1)  # Auto-detect workers
        ```

        Invalid parameters (will raise ValueError):
        ```python
        _validate_dataloader_params(0, 2, 4)    # batch_size = 0
        _validate_dataloader_params(32, 0, 4)   # prefetch_factor = 0
        _validate_dataloader_params(32, 2, -2)  # num_workers < -1
        ```

    Note:
        This validation is called automatically by create_dataloader() and
        should not typically be called directly by users.
    """
    if batch_size <= 0:
        raise ValueError(f"batch_size must be positive, got {batch_size}")
    if prefetch_factor <= 0:
        raise ValueError(
            f"prefetch_factor must be positive, got {prefetch_factor}"
        )
    if num_workers < -1:
        raise ValueError(f"num_workers must be >= -1, got {num_workers}")


def _calculate_adaptive_batch_size(current_batch_size: int,
    adaptive_enabled: bool,
    max_memory_limit_mb: float | None,
) -> int:
    """
Calculate optimal batch size based on available GPU memory to prevent
OOM. This function implements intelligent batch size adaptation that
monitors available GPU memory and adjusts the batch size to maximize
utilization while preventing out-of-memory errors during training. The
adaptive algorithm: 1. Checks if CUDA is available and adaptation is
enabled 2. Queries current available GPU memory with safety margin 3.
Estimates memory per sample (rough heuristic, needs refinement) 4.
Calculates maximum possible batch size within memory constraints 5.
Returns the minimum of requested and memory-limited batch size Args:
current_batch_size: Originally requested batch size. adaptive_enabled:
Whether to enable adaptive batch sizing. If False, returns
current_batch_size unchanged. max_memory_limit_mb: Optional maximum
memory limit in MB. If specified, limits memory usage even if more is
available. Returns: int: Adapted batch size that fits within memory
constraints. Always returns at least 1, even if memory is very
limited. Examples: Basic adaptation: ```python # With 8GB available,
might reduce batch size from 64 to 32 adapted =
_calculate_adaptive_batch_size(64, True, None) ``` With memory limit:
```python # Limit to 4GB even if more is available adapted =
_calculate_adaptive_batch_size(32, True, 4000.0) ``` Disabled
adaptation: ```python # Returns original batch size unchanged adapted
= _calculate_adaptive_batch_size(32, False, None) assert adapted == 32
``` Note: The current implementation uses a rough heuristic for memory
per sample. Future versions should implement more accurate memory
estimation based on actual model and data characteristics. Warnings
are issued when batch size is automatically reduced to help users
understand performance implications.
"""
    if not (adaptive_enabled and torch.cuda.is_available()):
        return current_batch_size

    # Calculate available memory (retain 10% for safety)
    current_available_gpu_mem = get_available_gpu_memory() * 0.9
    if max_memory_limit_mb is None:
        available_mb = current_available_gpu_mem
    else:
        available_mb = min(max_memory_limit_mb, current_available_gpu_mem)

    # Very rough heuristic for sample size in MB.
    # TODO: This should be made more sophisticated or configurable.
    approx_sample_size_mb = 4 * 0.001  # Example: 4MB, needs actual estimation
    if approx_sample_size_mb <= 0:
        warnings.warn(
            "Approximate sample size for adaptive batch is not positive. "
            "Adaptive batch sizing might not work as expected.",
            stacklevel=2,
        )
        return current_batch_size

    max_possible_batch_size = int(available_mb // approx_sample_size_mb)

    # Adjust batch size: take the minimum of current, and max possible based
    # on memory.
    new_batch_size = min(current_batch_size, max_possible_batch_size)
    new_batch_size = max(1, new_batch_size)  # Ensure at least 1

    if new_batch_size != current_batch_size:
        warnings.warn(
            f"Adaptive batch size adjusted to: {new_batch_size} (from "
            f"{current_batch_size}, limited by memory)",
            stacklevel=2,
        )
    return new_batch_size


def _configure_num_workers(requested_num_workers: int) -> int:
    """
Determine the optimal number of worker processes for data loading.
This function intelligently configures the number of DataLoader worker
processes based on system capabilities when automatic detection is
requested, or validates the manually specified worker count. Worker
count strategy: - Manual specification (>= 0): Use the provided value
directly - Auto-detection (-1): Use half of available CPU cores as
heuristic - Fallback: Default to 1 worker if CPU count cannot be
determined The heuristic of using half the CPU cores balances: - Data
loading throughput: More workers load data in parallel - System
resource usage: Leaves cores available for training - Memory
consumption: Each worker uses additional memory Args:
requested_num_workers: Requested number of workers. Use -1 for
automatic detection based on CPU cores. Use 0 for no multiprocessing
(main process only). Use positive integers for specific worker counts.
Returns: int: Actual number of workers to use. Always >= 0. Examples:
Automatic detection: ```python # On 8-core system, returns 4 workers
workers = _configure_num_workers(-1) ``` Manual specification:
```python # Returns exactly 6 workers workers =
_configure_num_workers(6) assert workers == 6 ``` No multiprocessing:
```python # Single-threaded data loading workers =
_configure_num_workers(0) assert workers == 0 ``` Note: The
half-CPU-cores heuristic works well for most scenarios but may need
adjustment for specific hardware configurations: - High-core count
systems: May want to limit workers further - Memory-constrained
systems: Consider fewer workers - Storage-limited systems: More
workers may not help Warnings are issued if CPU count detection fails
to help with debugging system-specific issues.
"""
    if requested_num_workers == -1:  # Auto-detect
        try:
            cpu_count = os.cpu_count()
            if cpu_count is not None:
                # Using half of the CPU cores is a common heuristic
                return max(1, cpu_count // 2)
            else:
                warnings.warn(
                    "Could not determine CPU count via os.cpu_count(), "
                    "defaulting num_workers to 1.",
                    stacklevel=2,
                )
                return 1
        except NotImplementedError:
            warnings.warn(
                "os.cpu_count() not implemented on this system, "
                "defaulting num_workers to 1.",
                stacklevel=2,
            )
            return 1
    return requested_num_workers


def _create_sampler_from_config(sampler_config_param: dict[str, Any] | None,
    dataset_param: Dataset[Any],
    world_size_param: int | None,
    rank_param: int | None,
    shuffle_param: bool,
) -> tuple[Sampler[Any] | None, bool]:
    """
    Create a PyTorch sampler from configuration and resolve shuffle conflicts.

    This function handles the complex process of instantiating custom samplers
    from configuration dictionaries while managing the interaction between
    samplers and shuffle settings. It supports various sampler types including
    distributed samplers for multi-GPU training.

    Sampler creation process:
    1. Extract sampler type from 'kind' key in configuration
    2. Prepare sampler-specific arguments and parameters
    3. Handle distributed training parameters (rank, world_size)
    4. Filter configuration to match expected sampler arguments
    5. Instantiate sampler via factory function
    6. Resolve shuffle conflicts (samplers override shuffle)

    Args:
        sampler_config_param: Dictionary containing sampler configuration.
            Must include 'kind' key specifying sampler type.
            Additional keys provide sampler-specific parameters.

        dataset_param: Dataset instance that the sampler will sample from.

        world_size_param: Total number of processes in distributed training.
            Required for distributed samplers, ignored otherwise.

        rank_param: Current process rank (0-based) in distributed training.
            Required for distributed samplers, ignored otherwise.

        shuffle_param: Original shuffle setting from crackseg.DataLoader
            config. May be overridden to False if sampler is used.

    Returns: tuple[Sampler[Any] | None, bool]: A tuple containing:
            - Sampler instance if configuration provided, None otherwise
            - Updated shuffle flag (False if sampler created, original
            otherwise)

    Examples:
        Distributed sampler configuration:
        ```python
        config = {
            "kind": "distributed",
            "shuffle": True,
            "drop_last": True
        }
        sampler, shuffle = _create_sampler_from_config(
            config, dataset, 4, 0, True
        )
        # Returns DistributedSampler instance, shuffle=False
        ```

        No sampler configuration:
        ```python
        sampler, shuffle = _create_sampler_from_config(
            None, dataset, None, None, True
        )
        # Returns None, shuffle=True (unchanged)
        ```

    Raises:
        Warnings are issued for:
        - Missing 'kind' key in sampler configuration
        - Conflicting shuffle and sampler settings

    Note:
        PyTorch DataLoader does not allow both shuffle=True and a custom
        sampler. This function automatically resolves the conflict by
        setting shuffle=False when a sampler is created.

        Distributed samplers require both rank and world_size parameters
        to function correctly in multi-process training scenarios.
    """
    sampler_instance: Sampler[Any] | None = None
    current_shuffle_status = shuffle_param

    if sampler_config_param:
        sampler_kind_str: str | None = sampler_config_param.get("kind")
        if sampler_kind_str:
            # Prepare args for SamplerFactoryArgs
            sfa_kwargs = sampler_config_param.copy()
            sfa_kwargs.pop(
                "kind", None
            )  # Remove kind as it's not in SamplerFactoryArgs

            if sampler_kind_str == "distributed":
                if world_size_param is not None:
                    sfa_kwargs["num_replicas"] = world_size_param
                if rank_param is not None:
                    sfa_kwargs["rank"] = rank_param
                # shuffle for distributed sampler is handled by
                # SamplerFactoryArgs default or sfa_kwargs

            # Ensure only valid keys for SamplerFactoryArgs are passed
            valid_sfa_keys = SamplerFactoryArgs.__annotations__.keys()
            filtered_sfa_kwargs = {
                k: v for k, v in sfa_kwargs.items() if k in valid_sfa_keys
            }

            sampler_args_obj = SamplerFactoryArgs(**filtered_sfa_kwargs)

            sampler_instance = sampler_factory(
                kind=sampler_kind_str,
                data_source=dataset_param,
                args=sampler_args_obj,
            )
            if current_shuffle_status:
                warnings.warn(
                    "Both sampler and shuffle are set. "
                    "Setting shuffle=False (PyTorch does not allow both).",
                    stacklevel=2,
                )
                current_shuffle_status = False
        else:
            warnings.warn(
                "Sampler configuration provided but 'kind' is missing or "
                f"None: {sampler_config_param}",
                stacklevel=2,
            )
    return sampler_instance, current_shuffle_status


def create_dataloader(dataset: Dataset[Any],
    batch_size: int = 32,
    config: DataLoaderConfig | None = None,
) -> DataLoader[Any]:
    """
Creates and configures a PyTorch DataLoader with sensible defaults.
Args: dataset (Dataset): The dataset from which to load the data.
batch_size (int): How many samples per batch to load. Default: 32.
config (DataLoaderConfig): Configuration object for the dataloader.
Returns: DataLoader: A configured PyTorch DataLoader instance. Raises:
ValueError: If batch_size or prefetch_factor are not positive, or if
num_workers is less than -1. ValueError: If both shuffle and sampler
are set (PyTorch limitation). Note: If using DistributedSampler, you
must call `set_epoch(epoch)` on the sampler at the beginning of each
epoch to ensure correct shuffling across processes. When using
fp16=True, you should wrap your training loop with
torch.cuda.amp.autocast() context manager.
"""
    if config is None:
        config = DataLoaderConfig()
    # --- Parameter Validation ---
    _validate_dataloader_params(
        batch_size, config.prefetch_factor, config.num_workers
    )

    # --- Memory Optimization (if requested) ---
    actual_batch_size = _calculate_adaptive_batch_size(
        current_batch_size=batch_size,
        adaptive_enabled=config.adaptive_batch_size,
        max_memory_limit_mb=config.max_memory_mb,
    )

    # --- Mixed Precision ---
    if config.fp16 and not torch.cuda.is_available():
        warnings.warn(
            "Mixed precision (fp16) requested but CUDA not available. "
            "Falling back to standard precision.",
            stacklevel=2,
        )

    # --- Determine num_workers ---
    actual_num_workers = _configure_num_workers(config.num_workers)

    # --- Determine pin_memory ---
    can_pin_memory = config.pin_memory and torch.cuda.is_available()
    if config.pin_memory and not can_pin_memory:
        warnings.warn(
            "pin_memory=True requires CUDA availability. "
            "Setting pin_memory=False.",
            stacklevel=2,
        )

    # --- Sampler logic ---
    sampler_instance, current_shuffle_status = _create_sampler_from_config(
        sampler_config_param=config.sampler_config,
        dataset_param=dataset,
        world_size_param=config.world_size,
        rank_param=config.rank,
        shuffle_param=config.shuffle,
    )

    # --- Create DataLoader ---
    actual_prefetch_factor: int | None = (
        config.prefetch_factor if actual_num_workers > 0 else None
    )
    dataloader_kwargs = (
        config.dataloader_extra_kwargs
        if config.dataloader_extra_kwargs
        else {}
    )
    dataloader_instance = DataLoader(
        dataset=dataset,
        batch_size=actual_batch_size,
        shuffle=current_shuffle_status if sampler_instance is None else False,
        sampler=sampler_instance,
        num_workers=actual_num_workers,
        pin_memory=can_pin_memory,
        prefetch_factor=actual_prefetch_factor,
        persistent_workers=True if actual_num_workers > 0 else False,
        **dataloader_kwargs,
    )

    return dataloader_instance
