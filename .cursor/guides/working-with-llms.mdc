---
description: 
globs: 
alwaysApply: false
---
# Working with LLMs

## Introduction
This guide provides best practices and prompt examples for collaborating with Large Language Models (LLMs) in this project. It is designed to help you leverage LLMs for code generation, refactoring, documentation, and testing, while ensuring alignment with the project's coding and workflow rules.

See also: [Glossary of Key Terms](mdc:glossary.mdc)

## Best Practices
- Always provide clear context: mention relevant files, rules, and expected outcomes.
- Reference the coding and workflow rules explicitly when needed.
- Break down large tasks into smaller, manageable prompts.
- Review and validate LLM-generated code before integrating it.
- Use the examples below as templates for your own prompts.

## Example Prompts

### 1. Refactor a Module
```
Refactor the file `src/model/unet.py` to improve modularity and readability according to the project's coding-preferences. Add or update docstrings in English. Do not change the public API.
```

### 2. Generate Documentation
```
Generate comprehensive docstrings for all functions and classes in `src/data/loader.py`, following the project's documentation standards.
```

### 3. Explain Code
```
Explain the logic and purpose of the function `train_model` in `src/training/loop.py`. Highlight any non-obvious implementation details.
```

### 4. Generate and Run Exhaustive Tests with pytest
```
For the following files: `src/model/unet.py`, `src/data/loader.py`, and `src/utils/metrics.py`, generate exhaustive unit tests using pytest. Ensure all major functionalities and edge cases are covered. Place the tests in the appropriate `tests/` directory, following the project's structure and naming conventions.

After generating the tests, run them using pytest. If any tests fail, iteratively fix the code or the tests until all tests pass successfully. Document any changes made during this process.
```

## Tips for Effective LLM Collaboration
- Always specify the files and the type of task (e.g., refactor, test, document).
- Reference the relevant rules or guides for context.
- For testing, request both the test code and the execution/validation steps.
- If the task is complex, ask the LLM to propose a plan before coding.

## FAQ
- **Q: How do I ensure the LLM follows project rules?**
  A: Reference the specific rule files (e.g., `coding-preferences.mdc`) in your prompt.
- **Q: Can I ask the LLM to run code or tests?**
  A: Yes, but always review the output and validate changes before merging.

---

For more details on project structure and rules, see:
- [Development Guide](mdc:development-guide.mdc)
- [Structural Guide](mdc:structural-guide.mdc)
- [Coding Preferences](mdc:../rules/coding-preferences.mdc)
- [Workflow Preferences](mdc:../rules/workflow-preferences.mdc)

